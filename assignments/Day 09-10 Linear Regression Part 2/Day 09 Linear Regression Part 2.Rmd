---
title: "Linear Regression Part 2"
author: "Carey Kopeikin and Matt Bardoe"
date: "4/13/2020 rev 1/25/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
```

#Linear Regression Day 2

What you will learn:
* To review scatterplots
* To review Simple linear regressions
* What a residual is and why it is important.
* How to use the summary function
* What R-squared means


#Warmup

We will start by using the data set USArrests. 
 
This data set contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973. Also given is the percent of the population living in urban areas.

The variables are 
* Murder: numeric	Murder arrests (per 100,000)
* Assault: numeric Assault arrests (per 100,000)
* UrbanPop:	numeric Percent urban population
* Rape: numeric Rape arrests (per 100,000)



```{r}
data(USArrests)

head(USArrests)

```

Our goal is to attempt to use the assault rate to predict the murder rate.


Create a scatterplot with labels making sure to put the explanatory and response variables on the correct axis. 

```{r}


```

Describe the shape, direction, and strength of the association:

*Your answer here.*





Is it appropriate to use correlation to talk about the relationship between these variables? Explain why or why not.

*Your answer here.*



Find the correlation between assault and murder.

```{r}

```

What does this tell you about the strength?

*Your answer here.*



Create a linear model and print out the results. Call this model: linearMod.murder.assault

```{r}


```



Find the equation of the line of best fit and explain in context what the slope and y-intercept tell us.

*Your answer here*






Make a scatterplot that includes the line of best fit.

```{r}

```



Predict the murder rate of states with 100 assaults per 100K people, 230 assaults per 100K people, and 40 assaults per 100K people

```{r}



```



#Residuals


So far we have been able to create a linear model and use it to make predictions. One key question is how good is that model? In order to determine that we can look at how wrong our predictions were. If we use the predict function without supplying a data frame of values, predict will output a prediction for each of the values in the original data frame.  

```{r}
USArrests$Predictions <- predict(linearMod.murder.assault)

USArrests$Predictions
```

Since we named the prediction using the name of the data frame and $ the predictions now appear in the data frame
```{r}
head(USArrests)
```

If we subtract the prediction from the actual value we can see how far off each of our predictions was.

```{r}
USArrests$How.far.off <- USArrests$Murder - USArrests$Predictions
head(USArrests)
```

The term we use in Statistics to describe these numbers is *residuals*.

If we use the ```resid``` function, then we can find the residuals quickly.

```{r}
USArrests$Residuals <- resid(linearMod.murder.assault)

head(USArrests)
```

Notice that the Residuals calculated by R using the resid function are exactly the same as those calculated by subtracting the predictions from the actual values.

This is how to create a visual of the residuals. They are the blue lines extending from the data points to the regression line. The length of the line is the value of the residual. 
```{r}
#Scatter plot
plot( USArrests$Murder ~ USArrests$Assault, 
     main = "Murder Rate vs Assault rate",
     xlab = "Assaults per 100k",
     ylab = "Murders per 100k",
     col = "Yellow",  
     bg = "red",
     pch = 21,
     cex = 1.5
      )

#Regression Line
abline(linearMod.murder.assault)

#Residuals
segments(USArrests$Assault, USArrests$Murder, # (x1, y1 )
         USArrests$Assault, USArrests$Predictions, #(x2, y2)
         col="blue",
         lwd = 2)
```
When the prediction was larger than the actual value the point will be below the line meaning we overestimated in our prediction this results in a negative residual.

When the prediction was smaller than the actual value the point will be above the line meaning we underestimated in our prediction this results in a positive residual.

Ideally if the model is good at predicting the response variable, the residuals should be small.



#Residual Plots

Looking at Residual Plots can also help us tell if we should not have been using a linear model after all. If a model tends to overestimate at low values of x and underestimate at high values our model may not be linear. If the model tends to be accurate at low values of x but poor at high values of x it may not be appropriate. 

To check a model, we can make a scatterplot with the predicted values as the x variable and the residuals as the y variable. Ideally the shape will be cloudlike showing no patterns at all.

It is helpful to draw a line at y = 0 so that we can see which residuals are positive and which are negative.

```{r}
#Residual Plot

plot( USArrests$Residuals ~ USArrests$Predictions, 
     main = "Residual Plot: Predicted vs Residuals",
     xlab = "Predicted Values",
     ylab = "Residuals",
     col = "blue",  
     bg = "red",
     pch = 21,
     cex = 1.5
      )

#Line at y = 0
abline(0, 0) 

```

That worked out very well! This is strong evidence that using a linear model was appropriate. 



Here is an example of a graph that originally looks like a linear model might be appropriate  

```{r}
data(faithful)
plot(faithful$eruptions ~ faithful$waiting,
     main = "Length of Eruption at Old Faithful as Predicted by Waiting Time ",
     xlab = "Waiting Time (in minutes)", 
     ylab = "Length of Eruption",
     col =  "orange",
     bg = "green",
     pch = 22,
     cex = 1.5
      )

```

But when we check the residuals there is a strange pattern.

```{r}

linearMod.eruptions.waiting <- lm(eruptions ~ waiting, data = faithful)

faithful$Predictions <- predict(linearMod.eruptions.waiting)
faithful$Residuals <- resid(linearMod.eruptions.waiting)


plot(faithful$Residuals ~ faithful$Predictions,
     main = "Residual Plot",
     xlab = "Predicted Values",
     ylab = "Residuals",
     col = "brown",  
     bg = "yellow",
     pch = 23,
     cex = 1.5
      )

abline(0,0)
```

Since there is a clear pattern in the Residual Plot, a linear model in not appropriate for this data. In order to analyze it we need a different method.




#The Summary Function
We can learn more about a regression model by using the summary function:

```{r}
print(linearMod.murder.assault)
summary(linearMod.murder.assault)
```

There is a lot of information that is printed out. The most important values for our analysis are:
* The Estimates which are the same values that you found earlier using the print() function
* The numbers under the column Pr(> t). These are the p-values of each variable. They essentially tell us the likelihood that the association we found could have been because of random variation. Note that the p-value at the bottom of the summary is something different that we will not examine in this course. 
* The stars next to the p-values. These tell us if and at what level the variables are significant. The key to understanding them is in the line that starts with Signif. codes.

From this summary we can see that:
* The slope of the regression line is .0419 and the y-intercept is .6316.
* The extremely low p-value by assault tells me that it is highly unlikely that it is just random variation that is masquerading as association. 
* The three stars tell us that the variable is significant at the .001 level.


#R-squared
Another key value we can see in the summary is R-squared (labeled Multiple R-squared in the summary table). R-squared is the percentage of the variation in the response variable is explained by the model. This value will always be between 0 and 1. The closer this value is to 1 the better the model is. 

Here is an example to see how to understand R-squared:

Say we did not do a regression and therefore had no idea what the relationship between assault and murder was. In order to guess the murder rate for a randomly selected state what would our best guess be? 

Since you know nothing else your guess should be the average murder rate. So how would we do if we just guessed the average murder rate for each state?

```{r}


```

Now we can compare the residuals to figure out how much better our regression model is than just guessing the mean. We can't just add them up to compare because due to some being positive and some being negative they will both add to 0.
```{r}
```
Note the only reason they do not add to exactly zero is due to rounding.

So we do what we have done several times already this year and square them before adding them up together.

```{r}
```

Our regression model has a much smaller sum of squared residuals than the just guessing model. It only has 
```{r}
```

That means that our model explains
```{r}

```
 
Running the summary function again we see that R-squared is 
```{r}
summary(linearMod.murder.assault)
```




#Your Turn

Now we will look at a data set that contains the monthly totals of car drivers in Great Britain killed or seriously injured Jan 1969 to Dec 1984. We will be looking to see if the price of gasoline (PetrolPrice) has an effect on the number of drivers killed (DriversKilled).

Load up the data set
```{r}
df.seatbelts <- as.data.frame(Seatbelts)
head(df.seatbelts)
```

Create a scatter plot of gas prices vs drivers killed. Make sure to put the explanatory and response variables on the correct axis.

```{r}


```

Is it appropriate to use a linear model to describe the association between the variables? Why or why not?

*Your answer here*



Create a linear model for the two variables.

```{r}
```


Find the predicted values and the residuals and add them to the data frame. 

```{r}

```


Make a graph of the predicted values and the residuals.

```{r}


```


Do you still think a linear model is appropriate? Why?



Find the summary of the linear model.

```{r}

```

Write the equation of the model



Could the association between gas price and driver deaths be due to random variation? Why or why not?





How good is the model at explaining the variation in driver deaths?



